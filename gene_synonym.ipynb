{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-06T08:13:49.360718Z",
     "start_time": "2024-12-06T08:13:48.973396Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import gzip\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T08:13:49.364739Z",
     "start_time": "2024-12-06T08:13:49.361722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.chdir('./Data/biomart')\n",
    "print(os.getcwd())"
   ],
   "id": "a10fa55cc995c658",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Python\\RAG\\Data\\biomart\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T08:13:52.158556Z",
     "start_time": "2024-12-06T08:13:49.365744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%bash\n",
    "bash reorder_mart.sh"
   ],
   "id": "e7e4de53d148403e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T08:13:52.162344Z",
     "start_time": "2024-12-06T08:13:52.159560Z"
    }
   },
   "cell_type": "code",
   "source": "os.chdir('../..')",
   "id": "3c1ffdd6f55f6feb",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T08:13:52.165826Z",
     "start_time": "2024-12-06T08:13:52.162344Z"
    }
   },
   "cell_type": "code",
   "source": "print(os.getcwd())",
   "id": "28325f30360eaeda",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Python\\RAG\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T08:13:52.169122Z",
     "start_time": "2024-12-06T08:13:52.165826Z"
    }
   },
   "cell_type": "code",
   "source": "Add_Synonyms = True",
   "id": "be19a3b2def135dc",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T08:13:52.712227Z",
     "start_time": "2024-12-06T08:13:52.169122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "input_file = './Data/biomart/to_be_converted/wikipathways-20240910-gmt-Homo_sapiens.gmt'\n",
    "output_file = './Data/biomart/to_be_converted/converted_wikipathways-20240910-gmt-Homo_sapiens.gmt'\n",
    "json_file = './Data/JSON/ncbi_id_to_symbol.json'\n",
    "\n",
    "# Load the gene ID to symbol dictionary from JSON\n",
    "with open(json_file, 'r') as f:\n",
    "    gene_dict = json.load(f)\n",
    "\n",
    "# Read the GMT input file\n",
    "columns = ['header', 'url'] + [f'gene_{i}' for i in range(1000)]  \n",
    "df = pd.read_csv(input_file, sep='\\t', header=None, names=columns, engine='python', dtype=str, na_filter=False)\n",
    "\n",
    "# Function to replace gene IDs with symbols\n",
    "def replace_gene_ids(gene_id):\n",
    "    return gene_dict.get(gene_id, gene_id)\n",
    "\n",
    "# Apply replacement function to gene columns\n",
    "gene_columns = df.columns[2:]\n",
    "for col in gene_columns:\n",
    "    df[col] = df[col].apply(replace_gene_ids)\n",
    "\n",
    "# Remove empty columns (if all values in a column are empty strings)\n",
    "df = df.loc[:, (df != '').any(axis=0)]\n",
    "\n",
    "# Remove empty rows for gene columns to prevent excess line breaks\n",
    "df = df.apply(lambda x: x.dropna().tolist(), axis=1).apply(pd.Series)\n",
    "\n",
    "# Save to the output file without excess newlines\n",
    "df.to_csv(output_file, sep='\\t', header=False, index=False, lineterminator='\\n')\n",
    "\n",
    "print(f'File conversion completed! Output saved to {output_file}')\n"
   ],
   "id": "47336cb2fad4f985",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File conversion completed! Output saved to ./Data/biomart/to_be_converted/converted_wikipathways-20240910-gmt-Homo_sapiens.gmt\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T08:13:52.715241Z",
     "start_time": "2024-12-06T08:13:52.712227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_file = './Data/biomart/to_be_converted/reordered_mart_export_2.txt.gz'  \n",
    "output_json = './Data/JSON/genes.json' \n",
    "output_file = './Data/biomart/genes_consolidated.txt.gz'"
   ],
   "id": "af13d65d29829a49",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T08:13:54.953822Z",
     "start_time": "2024-12-06T08:13:52.716248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ensure_dir(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if directory and not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Created directory: {directory}\")\n",
    "\n",
    "ensure_dir(output_json)\n",
    "ensure_dir(output_file)\n",
    "\n",
    "df = pd.read_csv(input_file, compression='gzip')\n",
    "print(f\"Successfully read input file: {input_file}\")\n",
    "\n",
    "df['Gene Synonym'] = df['Gene Synonym'].fillna('').astype(str).str.strip()\n",
    "\n",
    "df['Gene stable ID'] = df['Gene stable ID'].str.strip().str.upper()\n",
    "\n",
    "unique_gene_ids = df['Gene stable ID'].nunique()\n",
    "print(f\"Number of unique 'Gene stable ID's: {unique_gene_ids}\")\n",
    "# Grouping the data and applying transformations\n",
    "grouped = df.groupby('Gene stable ID').agg({\n",
    "    'Gene name': 'first',\n",
    "    'Gene description': 'first',\n",
    "    'Gene Synonym': lambda x: sorted(filter(None, x.unique())),\n",
    "    'NCBI gene (formerly Entrezgene) description': 'first',\n",
    "    'NCBI gene (formerly Entrezgene) ID': 'first'\n",
    "}).reset_index()\n",
    "# Ensure 'Gene Synonyms' are formatted correctly\n",
    "grouped.rename(columns={'Gene Synonym': 'Gene Synonyms'}, inplace=True)\n",
    "grouped['Gene Synonyms'] = grouped['Gene Synonyms'].apply(lambda x: f\"[{','.join(x)}]\" if x else \"[]\")\n",
    "\n",
    "# 1. Removing NCBI description unless Gene description is empty and NCBI description is not\n",
    "grouped['Gene description'] = grouped.apply(\n",
    "    lambda row: row['NCBI gene (formerly Entrezgene) description']\n",
    "    if pd.isna(row['Gene description']) and pd.notna(row['NCBI gene (formerly Entrezgene) description'])\n",
    "    else row['Gene description'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Removing descriptions between []. \n",
    "grouped['Gene description'] = grouped['Gene description'].str.replace(r'\\[.*?\\]', '', regex=True).str.strip()\n",
    "\n",
    "#Dropping the NCBI description column as it's no longer needed, and converting the ID to integer.\n",
    "grouped.drop(columns=['NCBI gene (formerly Entrezgene) description'], inplace=True)\n",
    "grouped['NCBI gene (formerly Entrezgene) ID'] = grouped['NCBI gene (formerly Entrezgene) ID'].astype('Int64')\n",
    "\n",
    "consolidated_entries = grouped.shape[0]\n",
    "print(f\"Number of consolidated entries: {consolidated_entries}\")\n",
    "\n",
    "if consolidated_entries != unique_gene_ids:\n",
    "    print(\"Warning: The number of consolidated entries does not match the number of unique 'Gene stable ID's.\")\n",
    "    print(f\"Unique 'Gene stable ID's: {unique_gene_ids}, Consolidated entries: {consolidated_entries}\")\n",
    "else:\n",
    "    print(\"Success: The number of consolidated entries matches the number of unique 'Gene stable ID's.\")\n",
    "\n",
    "genes_list = grouped.to_dict(orient='records')\n",
    "\n",
    "with open(output_json, 'w', encoding='utf-8') as f_json:\n",
    "    json.dump(genes_list, f_json, indent=4)\n",
    "print(f\"Consolidated JSON data has been saved to '{output_json}'.\")\n",
    "\n",
    "ordered_columns = [\n",
    "    'Gene stable ID',\n",
    "    'Gene name',\n",
    "    'Gene description',\n",
    "    #'Gene Synonyms',\n",
    "    #'NCBI gene (formerly Entrezgene) ID'\n",
    "]\n",
    "\n",
    "missing_columns = set(ordered_columns) - set(grouped.columns)\n",
    "if missing_columns:\n",
    "    print(f\"Error: Missing columns in the DataFrame: {missing_columns}\")\n",
    "    exit(1)\n",
    "\n",
    "grouped_ordered = grouped[ordered_columns]\n",
    "\n",
    "grouped_ordered.to_csv(output_file, index=False, sep=',', compression='gzip')\n",
    "print(f\"Consolidated TXT.GZ data has been saved to '{output_file}'.\")\n"
   ],
   "id": "fbc0088bb1a7e543",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read input file: ./Data/biomart/to_be_converted/reordered_mart_export_2.txt.gz\n",
      "Number of unique 'Gene stable ID's: 70611\n",
      "Number of consolidated entries: 70611\n",
      "Success: The number of consolidated entries matches the number of unique 'Gene stable ID's.\n",
      "Consolidated JSON data has been saved to './Data/JSON/genes.json'.\n",
      "Consolidated TXT.GZ data has been saved to './Data/biomart/genes_consolidated.txt.gz'.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T08:13:54.956966Z",
     "start_time": "2024-12-06T08:13:54.954405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "genes_json_path = './Data/JSON/genes.json'  \n",
    "input_gmt_path = './Data/biomart/to_be_converted/converted_wikipathways-20240910-gmt-Homo_sapiens.gmt'  \n",
    "output_gmt_path = './Data/biomart/wikipathways_synonyms_Homo_sapiens.gmt.gz' "
   ],
   "id": "7b41694328b7e1ee",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T08:13:55.185293Z",
     "start_time": "2024-12-06T08:13:54.956966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ensure_dir(output_gmt_path)\n",
    "\n",
    "# Load genes data\n",
    "with open(genes_json_path, 'r', encoding='utf-8') as f_json:\n",
    "    genes_data = json.load(f_json)\n",
    "\n",
    "# Create gene to synonyms mapping\n",
    "gene_to_synonyms = {}\n",
    "for entry in genes_data:\n",
    "    gene_name = entry.get('Gene name')\n",
    "    if gene_name is None:\n",
    "        continue\n",
    "    gene_name = gene_name.strip()\n",
    "    \n",
    "    synonyms_str = entry.get('Gene Synonyms') or ''\n",
    "    synonyms_str = synonyms_str.strip()\n",
    "    if synonyms_str.startswith('[') and synonyms_str.endswith(']'):\n",
    "        synonyms_str = synonyms_str[1:-1]\n",
    "    \n",
    "    synonyms = synonyms_str.split('_') if synonyms_str else []\n",
    "    synonyms = [syn.strip() for syn in synonyms if syn.strip()]\n",
    "    \n",
    "    gene_to_synonyms[gene_name] = synonyms\n",
    "\n",
    "print(f\"Loaded {len(gene_to_synonyms)} genes with synonyms.\")\n",
    "\n",
    "# Process GMT file and save as .gmt.gz\n",
    "def process_gmt(input_path, output_path, gene_synonyms_map):\n",
    "    base_url = \"https://www.wikipathways.org/instance/\"\n",
    "    with open(input_path, 'r', encoding='utf-8') as infile, gzip.open(output_path, 'wt', encoding='utf-8') as outfile:\n",
    "        for line_number, line in enumerate(infile, 1):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue  \n",
    "            parts = line.split('\\t')\n",
    "            if len(parts) < 3:\n",
    "                print(f\"Warning: Line {line_number} in GMT file does not have enough columns. Skipping.\")\n",
    "                continue\n",
    "            pathway_name_full, pathway_url_full, *genes = parts\n",
    "            \n",
    "            if '%' in pathway_name_full:\n",
    "                pathway_name = pathway_name_full.split('%')[0].strip()\n",
    "            else:\n",
    "                pathway_name = pathway_name_full.strip()\n",
    "            \n",
    "            if pathway_url_full.startswith(base_url):\n",
    "                pathway_url = pathway_url_full.replace(base_url, '').strip()\n",
    "            else:\n",
    "                pathway_url = pathway_url_full.strip()\n",
    "            \n",
    "            expanded_genes = []\n",
    "            for gene in genes:\n",
    "                gene = gene.strip()\n",
    "                if not gene:\n",
    "                    continue  \n",
    "                synonyms = gene_synonyms_map.get(gene, [])\n",
    "                if synonyms:\n",
    "                    expanded_gene = f\"[{gene}, \" + \", \".join(synonyms) + \"]\"\n",
    "                else:\n",
    "                    expanded_gene = f\"[{gene}]\"\n",
    "                expanded_genes.append(expanded_gene)\n",
    "            \n",
    "            # **4. Remove duplicate genes while preserving order**\n",
    "            seen = set()\n",
    "            unique_genes = []\n",
    "            for gene in expanded_genes:\n",
    "                if gene not in seen:\n",
    "                    seen.add(gene)\n",
    "                    unique_genes.append(gene)\n",
    "            \n",
    "            # **5. Assemble the new line**\n",
    "            new_line = '\\t'.join([pathway_name, pathway_url] + unique_genes)\n",
    "            outfile.write(new_line + '\\n')\n",
    "            \n",
    "            # **6. Progress Logging**\n",
    "            if line_number % 1000 == 0:\n",
    "                print(f\"Processed {line_number} lines.\")\n",
    "    print(f\"Finished processing GMT file. Output saved to '{output_path}'.\")\n",
    "\n",
    "process_gmt(input_gmt_path, output_gmt_path, gene_to_synonyms)"
   ],
   "id": "a6424487a5fbc2ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 41067 genes with synonyms.\n",
      "Finished processing GMT file. Output saved to './Data/biomart/wikipathways_synonyms_Homo_sapiens.gmt.gz'.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T08:13:55.187415Z",
     "start_time": "2024-12-06T08:13:55.185293Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "bb62beaff35e00ef",
   "outputs": [],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
